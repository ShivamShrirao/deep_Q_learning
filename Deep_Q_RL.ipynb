{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Q_RL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbuhMj8QkFUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "461edbdc-da9b-4b83-ff3a-48ec0423c85c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug 20 16:09:39 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6pXJGDekFNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ca07897d-3bf2-4359-eaf9-0719aa3b61cd"
      },
      "source": [
        "!git clone https://github.com/ShivamShrirao/dnn_from_scratch.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dnn_from_scratch'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (222/222), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 1440 (delta 143), reused 153 (delta 86), pack-reused 1218\u001b[K\n",
            "Receiving objects: 100% (1440/1440), 13.74 MiB | 7.56 MiB/s, done.\n",
            "Resolving deltas: 100% (958/958), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgT-5T6EkO8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c9867464-14e9-4293-a8e9-4ccd68310ff5"
      },
      "source": [
        "!git clone https://github.com/ShivamShrirao/deep_Q_learning_from_scratch.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep_Q_learning_from_scratch'...\n",
            "remote: Enumerating objects: 227, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/227)\u001b[K\rremote: Counting objects:   1% (3/227)\u001b[K\rremote: Counting objects:   2% (5/227)\u001b[K\rremote: Counting objects:   3% (7/227)\u001b[K\rremote: Counting objects:   4% (10/227)\u001b[K\rremote: Counting objects:   5% (12/227)\u001b[K\rremote: Counting objects:   6% (14/227)\u001b[K\rremote: Counting objects:   7% (16/227)\u001b[K\rremote: Counting objects:   8% (19/227)\u001b[K\rremote: Counting objects:   9% (21/227)\u001b[K\rremote: Counting objects:  10% (23/227)\u001b[K\rremote: Counting objects:  11% (25/227)\u001b[K\rremote: Counting objects:  12% (28/227)\u001b[K\rremote: Counting objects:  13% (30/227)\u001b[K\rremote: Counting objects:  14% (32/227)\u001b[K\rremote: Counting objects:  15% (35/227)\u001b[K\rremote: Counting objects:  16% (37/227)\u001b[K\rremote: Counting objects:  17% (39/227)\u001b[K\rremote: Counting objects:  18% (41/227)\u001b[K\rremote: Counting objects:  19% (44/227)\u001b[K\rremote: Counting objects:  20% (46/227)\u001b[K\rremote: Counting objects:  21% (48/227)\u001b[K\rremote: Counting objects:  22% (50/227)\u001b[K\rremote: Counting objects:  23% (53/227)\u001b[K\rremote: Counting objects:  24% (55/227)\u001b[K\rremote: Counting objects:  25% (57/227)\u001b[K\rremote: Counting objects:  26% (60/227)\u001b[K\rremote: Counting objects:  27% (62/227)\u001b[K\rremote: Counting objects:  28% (64/227)\u001b[K\rremote: Counting objects:  29% (66/227)\u001b[K\rremote: Counting objects:  30% (69/227)\u001b[K\rremote: Counting objects:  31% (71/227)\u001b[K\rremote: Counting objects:  32% (73/227)\u001b[K\rremote: Counting objects:  33% (75/227)\u001b[K\rremote: Counting objects:  34% (78/227)\u001b[K\rremote: Counting objects:  35% (80/227)\u001b[K\rremote: Counting objects:  36% (82/227)\u001b[K\rremote: Counting objects:  37% (84/227)\u001b[K\rremote: Counting objects:  38% (87/227)\u001b[K\rremote: Counting objects:  39% (89/227)\u001b[K\rremote: Counting objects:  40% (91/227)\u001b[K\rremote: Counting objects:  41% (94/227)\u001b[K\rremote: Counting objects:  42% (96/227)\u001b[K\rremote: Counting objects:  43% (98/227)\u001b[K\rremote: Counting objects:  44% (100/227)\u001b[K\rremote: Counting objects:  45% (103/227)\u001b[K\rremote: Counting objects:  46% (105/227)\u001b[K\rremote: Counting objects:  47% (107/227)\u001b[K\rremote: Counting objects:  48% (109/227)\u001b[K\rremote: Counting objects:  49% (112/227)\u001b[K\rremote: Counting objects:  50% (114/227)\u001b[K\rremote: Counting objects:  51% (116/227)\u001b[K\rremote: Counting objects:  52% (119/227)\u001b[K\rremote: Counting objects:  53% (121/227)\u001b[K\rremote: Counting objects:  54% (123/227)\u001b[K\rremote: Counting objects:  55% (125/227)\u001b[K\rremote: Counting objects:  56% (128/227)\u001b[K\rremote: Counting objects:  57% (130/227)\u001b[K\rremote: Counting objects:  58% (132/227)\u001b[K\rremote: Counting objects:  59% (134/227)\u001b[K\rremote: Counting objects:  60% (137/227)\u001b[K\rremote: Counting objects:  61% (139/227)\u001b[K\rremote: Counting objects:  62% (141/227)\u001b[K\rremote: Counting objects:  63% (144/227)\u001b[K\rremote: Counting objects:  64% (146/227)\u001b[K\rremote: Counting objects:  65% (148/227)\u001b[K\rremote: Counting objects:  66% (150/227)\u001b[K\rremote: Counting objects:  67% (153/227)\u001b[K\rremote: Counting objects:  68% (155/227)\u001b[K\rremote: Counting objects:  69% (157/227)\u001b[K\rremote: Counting objects:  70% (159/227)\u001b[K\rremote: Counting objects:  71% (162/227)\u001b[K\rremote: Counting objects:  72% (164/227)\u001b[K\rremote: Counting objects:  73% (166/227)\u001b[K\rremote: Counting objects:  74% (168/227)\u001b[K\rremote: Counting objects:  75% (171/227)\u001b[K\rremote: Counting objects:  76% (173/227)\u001b[K\rremote: Counting objects:  77% (175/227)\u001b[K\rremote: Counting objects:  78% (178/227)\u001b[K\rremote: Counting objects:  79% (180/227)\u001b[K\rremote: Counting objects:  80% (182/227)\u001b[K\rremote: Counting objects:  81% (184/227)\u001b[K\rremote: Counting objects:  82% (187/227)\u001b[K\rremote: Counting objects:  83% (189/227)\u001b[K\rremote: Counting objects:  84% (191/227)\u001b[K\rremote: Counting objects:  85% (193/227)\u001b[K\rremote: Counting objects:  86% (196/227)\u001b[K\rremote: Counting objects:  87% (198/227)\u001b[K\rremote: Counting objects:  88% (200/227)\u001b[K\rremote: Counting objects:  89% (203/227)\u001b[K\rremote: Counting objects:  90% (205/227)\u001b[K\rremote: Counting objects:  91% (207/227)\u001b[K\rremote: Counting objects:  92% (209/227)\u001b[K\rremote: Counting objects:  93% (212/227)\u001b[K\rremote: Counting objects:  94% (214/227)\u001b[K\rremote: Counting objects:  95% (216/227)\u001b[K\rremote: Counting objects:  96% (218/227)\u001b[K\rremote: Counting objects:  97% (221/227)\u001b[K\rremote: Counting objects:  98% (223/227)\u001b[K\rremote: Counting objects:  99% (225/227)\u001b[K\rremote: Counting objects: 100% (227/227)\u001b[K\rremote: Counting objects: 100% (227/227), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 227 (delta 140), reused 157 (delta 70), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (227/227), 182.60 KiB | 365.00 KiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQZiX7WgkQeu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "48789ed3-cfcf-4d80-9109-b858eafee956"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caNfRIj1kRcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "397930a8-eb0a-4d1f-80a7-4eadbf019ba3"
      },
      "source": [
        "%cd deep_Q_learning_from_scratch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deep_Q_learning_from_scratch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzhhtvRQkWJW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6d0732d7-9be6-4dc2-c5c0-de3ebac869eb"
      },
      "source": [
        "!git pull origin master"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/ShivamShrirao/deep_Q_learning_from_scratch\n",
            " * branch            master     -> FETCH_HEAD\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0SnQz--kXCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "\n",
        "from settings import *\n",
        "from agent import *\n",
        "from experience import *"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc4bwkXTkX7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9befd272-e464-4db4-f128-a27ef19c943f"
      },
      "source": [
        "agt = Agent(actions=[0,2,3], epsilon=1, min_epsilon=0.1, eps_decay=2e-6, target_update_thresh=1000)\n",
        "D_exp = ReplayMemory(capacity=1_000_000, nlap=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽⎽\n",
            "Layer (type)               Output Shape             Activation        Param #\n",
            "==========================================================================================\n",
            "- InputLayer(InputLayer)  (None, 80, 80, 4)          echo             0\n",
            "__________________________________________________________________________________________\n",
            "0 Conv2D(Conv2D)          (None, 40, 40, 32)         relu             1184\n",
            "__________________________________________________________________________________________\n",
            "1 Conv2D(Conv2D)          (None, 20, 20, 64)         relu             18496\n",
            "__________________________________________________________________________________________\n",
            "2 Conv2D(Conv2D)          (None, 10, 10, 128)        relu             73856\n",
            "__________________________________________________________________________________________\n",
            "3 Flatten(Flatten)        (None, 12800)              echo             0\n",
            "__________________________________________________________________________________________\n",
            "4 Dense(Dense)            (None, 512)                relu             6554112\n",
            "__________________________________________________________________________________________\n",
            "5 Dense(Dense)            (None, 3)                  tanh             1539\n",
            "==========================================================================================\n",
            "Total Params: 6,649,187\n",
            "Trainable Params: 6,649,187\n",
            "Non-trainable Params: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDlH0rWlH2Kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8df8494a-ac31-451f-f70a-327230d57874"
      },
      "source": [
        "D_exp.current_state.nbytes/1024/1024/1024"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.9604644775390625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFlEoOqOkbcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do2kpfL9Yd_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "791df6ac-0abd-4433-ed06-90e1e0b6984f"
      },
      "source": [
        "D_exp.len"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "533590"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-zscT4Tkd2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fb730589-c5b7-4eba-d412-3e246cef9dde"
      },
      "source": [
        "for i_episode in range(250):\n",
        "    obinit = env.reset()\n",
        "    if not i_episode:\n",
        "        observation = obinit\n",
        "        state = preproc_obsv(observation)\n",
        "        state_que = deque([], maxlen=NFRAMES)\n",
        "        for i in range(NFRAMES):\n",
        "            state_que.append(state)\n",
        "    ep_score = 0\n",
        "    start = time.time()\n",
        "    for t in range(10_000):\n",
        "        s_s = time.time()\n",
        "#         env.render()\n",
        "        state = preproc_obsv(observation)\n",
        "        state_que.append(state)\n",
        "        action = agt.get_action(state_que)\n",
        "        next_observation, reward, done, info = env.step(action)\n",
        "        ep_score += reward\n",
        "\n",
        "        D_exp.store_transition(state, agt.actions.index(action), reward, done)\n",
        "        observation = next_observation\n",
        "\n",
        "        if (D_exp.len-D_exp.idx_len) > BATCH_SIZE:\n",
        "            grads = agt.train(D_exp, BATCH_SIZE)\n",
        "        print('\\r', t, ep_score, end='  ')\n",
        "        if done:\n",
        "            break\n",
        "    print(f\"\\rEpisode {i_episode+1} finished after {t+1} timesteps, Score: {ep_score}, Epsilon: {agt.epsilon:.6f}, Time: {time.time()-start:.2f}\")\n",
        "    if not i_episode%8:\n",
        "        agt.model.save_weights(\"/content/drive/My Drive/model.w8s\")\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 1 finished after 1721 timesteps, Score: -18.0, Epsilon: 0.976948, Time: 15.16\n",
            "Episode 2 finished after 1108 timesteps, Score: -21.0, Epsilon: 0.974732, Time: 9.86\n",
            "Episode 3 finished after 1278 timesteps, Score: -21.0, Epsilon: 0.972176, Time: 11.17\n",
            "Episode 4 finished after 1249 timesteps, Score: -21.0, Epsilon: 0.969678, Time: 10.98\n",
            "Episode 5 finished after 1513 timesteps, Score: -19.0, Epsilon: 0.966652, Time: 13.40\n",
            "Episode 6 finished after 1780 timesteps, Score: -17.0, Epsilon: 0.963092, Time: 15.74\n",
            "Episode 7 finished after 1389 timesteps, Score: -20.0, Epsilon: 0.960314, Time: 12.26\n",
            " 323 -4.0  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ8xVnmIM-d_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agt.epsilon = 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwhwhRmdbUjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "13dadbed-9723-4e33-c04e-037599281204"
      },
      "source": [
        "for i_episode in range(3):\n",
        "    obinit = env.reset()\n",
        "    if not i_episode:\n",
        "        observation = obinit\n",
        "        state = preproc_obsv(observation)\n",
        "        state_que = deque([], maxlen=NFRAMES)\n",
        "        for i in range(NFRAMES):\n",
        "            state_que.append(state)\n",
        "    ep_score = 0\n",
        "    preds = []\n",
        "    reward_history = []\n",
        "    start = time.time()\n",
        "    t = -1\n",
        "    while 1:\n",
        "        t+=1\n",
        "        # env.render()\n",
        "        state = preproc_obsv(observation)\n",
        "        state_que.append(state)\n",
        "        # action = agt.get_action(state_que)\n",
        "        out = agt.predict(state_que)\n",
        "        pidx = cp.argmax(out[0]).item()\n",
        "        preds.append(out[0][pidx].item())\n",
        "        action = agt.actions[pidx]\n",
        "        next_observation, reward, done, info = env.step(action)\n",
        "        ep_score += reward\n",
        "        reward_history.append(reward)\n",
        "        observation = next_observation\n",
        "        # time.sleep(1/fps)\n",
        "        if done:\n",
        "            break\n",
        "        print('\\r', t, action, ep_score, end='  ')\n",
        "    print(f\"\\rEpisode {i_episode+1} finished after {t+1} timesteps, Score: {ep_score}, Epsilon: {agt.epsilon:.6f}, Time: {time.time()-start:.2f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 1 finished after 8859 timesteps, Score: -10.0, Epsilon: 0.000000, Time: 19.87\n",
            "Episode 2 finished after 10000 timesteps, Score: -12.0, Epsilon: 0.000000, Time: 21.77\n",
            "Episode 3 finished after 10000 timesteps, Score: -10.0, Epsilon: 0.000000, Time: 21.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DqektqyH6Wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}